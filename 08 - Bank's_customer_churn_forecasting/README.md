# Прогнозирование оттока клиентов банка

### Статус проекта

`Завершен`

### Используемые инструменты

`Pandas`, `Matplotlib`, `Sklearn`, `Numpy`

## Цель

Из «Бета-Банка» стали уходить клиенты. В соответствии с расчетами банковских маркетологов: сохранять текущих клиентов дешевле, чем привлекать новых. Необходимо спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. В распоряжение предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. Постройте модель с предельно большим значением F1-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте F1-меру на тестовой выборке самостоятельно. Дополнительно измеряйте AUC-ROC, сравнивайте её значение с F1-мерой.

## Итоги

В данном проекте была разработана модель, которая делает предсказания о том, уйдет ли клиент из банка "Бета-банк" на основе исторических данных об уходе клиентов из банков.

1. Было проведено изучение данных, с которыми мы впоследствии работали.
2. Была проведена обработка данных.
3. Были исследованы три модели без учета баланса классов (`DecisionTreeClassifier`, `RandomForestClassifier` и `LogisticRegression`). Рассчитаны метрики классификации моделей и определены оптимальные параметры на валидационной выборке.
4. Оптимальная модель `RandomForestClassifier` с количеством деревьев в лесу `n_estimators` 20 и глубиной леса `max_Depth` 10 была исследована с учетом баланса классов. Рассчитаны значения метрик на валидационной выборке:
    - Accuracy достигла значения (0.8180)
    - Мера F1 достигла значения (0.6000)
    - ROC AUC достигла значения (0.8482) 
5. При применении указанной модели к тестовой выборки были достигнуты показатели:
    - Accuracy достигла значения (0.8225)
    - Мера F1 достигла значения (0.6154)
    - ROC AUC достигла значения (0.8630)
7. После проверки модели случайного леса на адекватность было установлено, что модель случайного леса с гиперпараметрами n_estimators = 20 и max_depth = 10 работает лучше, чем стратегии случайного прогнозирования классификатора DummyClassifier().
8. После проведения проверка модели на тестовой выборке и на расширенной выборке был сделан вывод, что модель работает достаточно хорошо — показатель метрики f1_score удалось достигнуть выше, чем было заявлено в требованиях (минимальное требование к этой метрике было 0.59, модель дает лучший результат). Хороший реузультат достигнут также по метрике roc_auc_score. 
