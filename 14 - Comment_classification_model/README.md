# Обучение модели классификации комментариев

### Статус проекта

`Завершен`

### Используемые инструменты

`Pandas`, `Matplotlib`, `Nltk`, `Plotly`, `Numpy`, `Tqdm`, `Sklearn`, `Torch transformers`, `Re`, `Lightgbm`, `Catboost`

## Цель

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.
Обучите модель классифицировать комментарии на позитивные и негативные. В распоряжении имеется набор данных с разметкой о токсичности правок.


## Итоги

В данном проекте были построены модели, предсказывающие токсичность комментариев.

1. Были изучены и подготовлены данные, что включало в себя:
    - загрузка,изучение и первичный анализ представленных данных; • проверка данных на пропуски; • проведение предобработки текстов (удаление лишних символов, стоп-слов);
    - проведение визуализацию, показывающая какие слова чаще всего встречаются в комментариях разной тональности.
    из за того, что исходные данные обладают большим количеством признаков на этапе подготовки очищенного набора данных для обучения моделей было проведено изменение весов и ресемплирование что позволило при обучении моделей добиться приемлемого времени расчета моделей с учетом ограничений на вычислительные ресурсы

2.  Были обучены следующие модели:
    - LogisticRegression;
    - DecisionTreeClassifier;
    - CatBoostClassifier;
    - SGDClassifier

3. По результатам использования четырех моделей можно сделать следующий вывод:
    - так как TF-IDF превращают текст в численные значения, лучшими моделями стали LogisticRegression и SGDClassifier при работе которых достигнуты значения F1 на валидации 0.7595532039976484 и 0.752649191299498 соответственно;
    - на тестовой выбоке по метрике F1 лучше всего себя показал LogisticRegression по сравнению с SGDClassifier    всего на 0.02. При не существенной разницые в показателе F1 данная модель обладает лучшими показателями Precision и Accuracy (0.7149532710280374 против 0.6832080200501253 и 0.9462635124549584 против 0.9430675231082563 соответственно). Таким образом, можно сделать вывод, что указанная модель (LogisticRegression) лучше находит токсичные комментарии.      - одновременно модель SGDClassifier показал себя лучше в ROC AUC (0.9664737359623974 против 0.9612024316657651) и Recall(0.831351021652943 против 0.7932296431838975) метриках. Это означает, что указанная  модель способна обработать больше записей;
    - использование моделей DecisionTreeClassifier и CatBoostClassifier дало худший результат по сравнению с LogisticRegression и SGDClassifier.
